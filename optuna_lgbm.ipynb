{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils import resample\n",
    "import optuna\n",
    "from lightgbm import early_stopping, log_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Files\n",
    "\n",
    "Download the csv files into the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv shape is  (1697533, 9)\n",
      "test.csv shape is  (212192, 2)\n",
      "\n",
      "        Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0   914403  B0009W5KHM   AV6QDP8Q0ONK4                     2   \n",
      "1   354887  6303079709  A2I8RXJN80A2D2                     0   \n",
      "2  1407653  B004H0M2XC  A3FHV3RV8Z12E6                     0   \n",
      "3  1377458  B003ZJ9536  A12VLTA3ZHVPUY                     1   \n",
      "4   475323  630574453X  A13NM1PES9OXVN                     2   \n",
      "\n",
      "   HelpfulnessDenominator        Time  \\\n",
      "0                       2  1341014400   \n",
      "1                       0  1168819200   \n",
      "2                       0  1386201600   \n",
      "3                       1  1348704000   \n",
      "4                       3   970012800   \n",
      "\n",
      "                                         Summary  \\\n",
      "0                                  GOOD FUN FILM   \n",
      "1                                   Movie Review   \n",
      "2             When is it a good time to Consent?   \n",
      "3                                          TRUTH   \n",
      "4  Intelligent and bittersweet -- stays with you   \n",
      "\n",
      "                                                Text  Score  \n",
      "0  While most straight to DVD films are not worth...    5.0  \n",
      "1  I have wanted this one for sometime, also.  I ...    5.0  \n",
      "2  Actually this was a pretty darn good indie fil...    4.0  \n",
      "3  Episodes 37 to 72 of the series press on in a ...    5.0  \n",
      "4  I was really impressed with this movie, but wa...    3.0  \n",
      "\n",
      "        Id  Score\n",
      "0  1323432    NaN\n",
      "1  1137299    NaN\n",
      "2  1459366    NaN\n",
      "3   931601    NaN\n",
      "4  1311995    NaN\n",
      "\n",
      "                 Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
      "count  1.697533e+06          1.697533e+06            1.697533e+06   \n",
      "mean   8.487660e+05          3.569048e+00            5.301422e+00   \n",
      "std    4.900357e+05          1.727883e+01            2.024445e+01   \n",
      "min    0.000000e+00          0.000000e+00            0.000000e+00   \n",
      "25%    4.243830e+05          0.000000e+00            0.000000e+00   \n",
      "50%    8.487660e+05          1.000000e+00            1.000000e+00   \n",
      "75%    1.273149e+06          3.000000e+00            5.000000e+00   \n",
      "max    1.697532e+06          6.084000e+03            6.510000e+03   \n",
      "\n",
      "               Time         Score  \n",
      "count  1.697533e+06  1.485341e+06  \n",
      "mean   1.262422e+09  4.110517e+00  \n",
      "std    1.289277e+08  1.197651e+00  \n",
      "min    8.793792e+08  1.000000e+00  \n",
      "25%    1.164413e+09  4.000000e+00  \n",
      "50%    1.307491e+09  5.000000e+00  \n",
      "75%    1.373242e+09  5.000000e+00  \n",
      "max    1.406074e+09  5.000000e+00  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVERYTHING IS PROPERLY SET UP! YOU ARE READY TO START\n"
     ]
    }
   ],
   "source": [
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "testingSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "print(\"train.csv shape is \", trainingSet.shape)\n",
    "print(\"test.csv shape is \", testingSet.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(trainingSet.head())\n",
    "print()\n",
    "print(testingSet.head())\n",
    "\n",
    "print()\n",
    "\n",
    "print(trainingSet.describe())\n",
    "\n",
    "trainingSet['Score'].value_counts().plot(kind='bar', legend=True, alpha=.5)\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"EVERYTHING IS PROPERLY SET UP! YOU ARE READY TO START\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    \"\"\" to perform sentiment analysis on the review \"\"\"\n",
    "    blob = TextBlob(str(text))\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to(df):\n",
    "    # This is where you can do all your feature extraction\n",
    "\n",
    "    df['Helpfulness'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "    df['Helpfulness'] = df['Helpfulness'].fillna(0)\n",
    "\n",
    "    # Review length (number of words in review text)\n",
    "    df['ReviewLength'] = df['Text'].apply(lambda x: len(str(x).split()))\n",
    "    df['ReviewLength'] = df['ReviewLength'].fillna(0)\n",
    "\n",
    "    df['HelpfulnessLengthInteraction'] = df['Helpfulness'] * df['ReviewLength']\n",
    "    df['HelpfulnessLengthInteraction'] = df['HelpfulnessLengthInteraction'].fillna(0)\n",
    "\n",
    "    # Summary length (number of words in summary text)\n",
    "    df['SummaryLength'] = df['Summary'].apply(lambda x: len(str(x).split()))\n",
    "    df['SummaryLength'] = df['SummaryLength'].fillna(0)\n",
    "\n",
    "    # Time features\n",
    "    df['Year'] = pd.to_datetime(df['Time'], unit='s').dt.year\n",
    "    df['Month'] = pd.to_datetime(df['Time'], unit='s').dt.month\n",
    "\n",
    "    # Sentiment Scores\n",
    "    df[['text_polarity', 'text_subjectivity']] = df['Text'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "    df[['summary_polarity', 'summary_subjectivity']] = df['Summary'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "\n",
    "    df['text_polarity'] = df['text_polarity'].fillna(0)\n",
    "    df['text_subjectivity'] = df['text_subjectivity'].fillna(0)\n",
    "    df['summary_polarity'] = df['summary_polarity'].fillna(0)\n",
    "    df['summary_subjectivity'] = df['summary_subjectivity'].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the feature extracted files if they've already been generated\n",
    "if exists('./data/X_train.csv'):\n",
    "    X_train = pd.read_csv(\"./data/X_train.csv\")\n",
    "if exists('./data/X_submission.csv'):\n",
    "    X_submission = pd.read_csv(\"./data/X_submission.csv\")\n",
    "\n",
    "else:\n",
    "\n",
    "    # Process the DataFrame\n",
    "    train = add_features_to(trainingSet)\n",
    "\n",
    "    # Merge on Id so that the submission set can have feature columns as well\n",
    "    X_submission = pd.merge(train, testingSet, left_on='Id', right_on='Id')\n",
    "    X_submission = X_submission.drop(columns=['Score_x'])\n",
    "    X_submission = X_submission.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "    # The training set is where the score is not null\n",
    "    X_train =  train[train['Score'].notnull()]\n",
    "    # The training set where the Summary field is not null\n",
    "    X_train.loc[:, 'Summary'] = X_train['Summary'].fillna('')\n",
    "    # The training set where the Text field is not null\n",
    "    X_train.loc[:, 'Text'] = X_train['Text'].fillna('')\n",
    "\n",
    "    X_submission.to_csv(\"./data/X_submission.csv\", index=False)\n",
    "    X_train.to_csv(\"./data/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample + Split into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train.drop(columns=['Score']),\n",
    "    X_train['Score'],\n",
    "    test_size=1/4.0,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# X_train: A subset of the dataset’s features used for training the model.\n",
    "# X_test: A subset of the dataset’s features used for testing the model.\n",
    "# Y_train: The corresponding labels or target values for X_train.\n",
    "# Y_test: The corresponding labels or target values for X_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Helpfulness', 'ReviewLength', 'HelpfulnessLengthInteraction', 'SummaryLength',\n",
    "            'Year', 'Month', 'text_polarity', 'text_subjectivity', 'summary_polarity', 'summary_subjectivity']\n",
    "\n",
    "X_train_select = X_train[features]\n",
    "X_test_select = X_test[features]\n",
    "X_submission_select = X_submission[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original training data into training and validation sets for Optuna\n",
    "X_train_optuna, X_val_optuna, Y_train_optuna, Y_val_optuna = train_test_split(\n",
    "    X_train_select, Y_train, test_size=0.2, random_state=42, stratify=Y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 5,  # Number of star rating classes\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 100),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Create the LGBMClassifier with suggested parameters\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    \n",
    "    # Train with early stopping via callbacks\n",
    "    model.fit(\n",
    "        X_train_select, Y_train, \n",
    "        eval_set=[(X_test_select, Y_test)], \n",
    "        eval_metric=\"multi_logloss\",\n",
    "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    preds = model.predict(X_test_select)\n",
    "    accuracy = accuracy_score(Y_test, preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:33:41,311] A new study created in memory with name: no-name-93433ada-5d03-402a-96bb-896de97a609e\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.976978390539001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.976978390539001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7790314508553454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7790314508553454\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.976978390539001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.976978390539001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7790314508553454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7790314508553454\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.976978390539001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.976978390539001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7790314508553454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7790314508553454\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.02705\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.976978390539001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.976978390539001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7790314508553454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7790314508553454\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:33:55,519] Trial 0 finished with value: 0.5759554689014801 and parameters: {'num_leaves': 34, 'learning_rate': 0.04455645425572091, 'feature_fraction': 0.976978390539001, 'bagging_fraction': 0.7790314508553454, 'bagging_freq': 1, 'min_data_in_leaf': 37}. Best is trial 0 with value: 0.5759554689014801.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7760601433928446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7760601433928446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9540177972153381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9540177972153381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7760601433928446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7760601433928446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9540177972153381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9540177972153381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7760601433928446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7760601433928446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9540177972153381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9540177972153381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.06002\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7760601433928446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7760601433928446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9540177972153381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9540177972153381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:34:25,380] Trial 1 finished with value: 0.563602774845423 and parameters: {'num_leaves': 113, 'learning_rate': 0.013090620853858348, 'feature_fraction': 0.7760601433928446, 'bagging_fraction': 0.9540177972153381, 'bagging_freq': 5, 'min_data_in_leaf': 81}. Best is trial 0 with value: 0.5759554689014801.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7815410137205112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7815410137205112\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7551241925790445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7551241925790445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7815410137205112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7815410137205112\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7551241925790445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7551241925790445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7815410137205112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7815410137205112\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7551241925790445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7551241925790445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01128\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7815410137205112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7815410137205112\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7551241925790445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7551241925790445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:34:48,802] Trial 2 finished with value: 0.5821089256091518 and parameters: {'num_leaves': 85, 'learning_rate': 0.0805731305753479, 'feature_fraction': 0.7815410137205112, 'bagging_fraction': 0.7551241925790445, 'bagging_freq': 5, 'min_data_in_leaf': 97}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7258544590293206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258544590293206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7350210649394974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7350210649394974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7258544590293206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258544590293206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7350210649394974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7350210649394974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7258544590293206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258544590293206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7350210649394974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7350210649394974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.02795\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7258544590293206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258544590293206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7350210649394974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7350210649394974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:35:07,179] Trial 3 finished with value: 0.5763971174354223 and parameters: {'num_leaves': 107, 'learning_rate': 0.028012019336857413, 'feature_fraction': 0.7258544590293206, 'bagging_fraction': 0.7350210649394974, 'bagging_freq': 1, 'min_data_in_leaf': 45}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7043689826680481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7043689826680481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8972537362568425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8972537362568425\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7043689826680481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7043689826680481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8972537362568425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8972537362568425\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7043689826680481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7043689826680481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8972537362568425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8972537362568425\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.05896\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7043689826680481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7043689826680481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8972537362568425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8972537362568425\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:35:20,093] Trial 4 finished with value: 0.5635973888876921 and parameters: {'num_leaves': 36, 'learning_rate': 0.017335991733982415, 'feature_fraction': 0.7043689826680481, 'bagging_fraction': 0.8972537362568425, 'bagging_freq': 1, 'min_data_in_leaf': 48}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7172007779611668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7172007779611668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7126674671082074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7126674671082074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7172007779611668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7172007779611668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7126674671082074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7126674671082074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7172007779611668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7172007779611668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7126674671082074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7126674671082074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.05223\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7172007779611668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7172007779611668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7126674671082074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7126674671082074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:35:47,089] Trial 5 finished with value: 0.5669743843850313 and parameters: {'num_leaves': 119, 'learning_rate': 0.015488538891487668, 'feature_fraction': 0.7172007779611668, 'bagging_fraction': 0.7126674671082074, 'bagging_freq': 3, 'min_data_in_leaf': 81}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9882491569723721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9882491569723721\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.750987501482537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750987501482537\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9882491569723721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9882491569723721\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.750987501482537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750987501482537\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9882491569723721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9882491569723721\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.750987501482537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750987501482537\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9882491569723721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9882491569723721\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.750987501482537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750987501482537\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:36:13,109] Trial 6 finished with value: 0.5817857681452916 and parameters: {'num_leaves': 111, 'learning_rate': 0.07037123482148432, 'feature_fraction': 0.9882491569723721, 'bagging_fraction': 0.750987501482537, 'bagging_freq': 4, 'min_data_in_leaf': 57}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9080532207289892, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080532207289892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7345027928369394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7345027928369394\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9080532207289892, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080532207289892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7345027928369394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7345027928369394\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9080532207289892, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080532207289892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7345027928369394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7345027928369394\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.03888\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9080532207289892, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080532207289892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7345027928369394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7345027928369394\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:36:26,842] Trial 7 finished with value: 0.5714501152594954 and parameters: {'num_leaves': 23, 'learning_rate': 0.033338608819917195, 'feature_fraction': 0.9080532207289892, 'bagging_fraction': 0.7345027928369394, 'bagging_freq': 3, 'min_data_in_leaf': 52}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9096224808285587, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9096224808285587\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7497922200607271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7497922200607271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9096224808285587, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9096224808285587\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7497922200607271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7497922200607271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9096224808285587, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9096224808285587\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7497922200607271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7497922200607271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01962\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9096224808285587, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9096224808285587\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7497922200607271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7497922200607271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:36:56,367] Trial 8 finished with value: 0.5790470086390762 and parameters: {'num_leaves': 145, 'learning_rate': 0.034684406792140465, 'feature_fraction': 0.9096224808285587, 'bagging_fraction': 0.7497922200607271, 'bagging_freq': 4, 'min_data_in_leaf': 81}. Best is trial 2 with value: 0.5821089256091518.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7696162919797442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7696162919797442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775790808568749, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775790808568749\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7696162919797442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7696162919797442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775790808568749, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775790808568749\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7696162919797442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7696162919797442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775790808568749, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775790808568749\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01022\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7696162919797442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7696162919797442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775790808568749, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775790808568749\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:37:21,698] Trial 9 finished with value: 0.582297434129737 and parameters: {'num_leaves': 107, 'learning_rate': 0.08490846650862624, 'feature_fraction': 0.7696162919797442, 'bagging_fraction': 0.7775790808568749, 'bagging_freq': 4, 'min_data_in_leaf': 66}. Best is trial 9 with value: 0.582297434129737.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8216309155488173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216309155488173\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8308536538853354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8308536538853354\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8216309155488173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216309155488173\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8308536538853354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8308536538853354\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8216309155488173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216309155488173\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8308536538853354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8308536538853354\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01196\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8216309155488173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216309155488173\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8308536538853354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8308536538853354\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:37:41,294] Trial 10 finished with value: 0.5815434000473965 and parameters: {'num_leaves': 62, 'learning_rate': 0.09698395665325647, 'feature_fraction': 0.8216309155488173, 'bagging_fraction': 0.8308536538853354, 'bagging_freq': 7, 'min_data_in_leaf': 22}. Best is trial 9 with value: 0.582297434129737.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7931914078889307, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7931914078889307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8251782832956129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8251782832956129\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7931914078889307, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7931914078889307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8251782832956129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8251782832956129\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7931914078889307, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7931914078889307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8251782832956129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8251782832956129\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01339\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7931914078889307, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7931914078889307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8251782832956129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8251782832956129\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:38:06,376] Trial 11 finished with value: 0.5812767951397118 and parameters: {'num_leaves': 80, 'learning_rate': 0.06478506526795455, 'feature_fraction': 0.7931914078889307, 'bagging_fraction': 0.8251782832956129, 'bagging_freq': 6, 'min_data_in_leaf': 99}. Best is trial 9 with value: 0.582297434129737.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7664943720204859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7664943720204859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8025891171923445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8025891171923445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7664943720204859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7664943720204859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8025891171923445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8025891171923445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7664943720204859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7664943720204859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8025891171923445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8025891171923445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01048\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7664943720204859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7664943720204859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8025891171923445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8025891171923445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:38:29,192] Trial 12 finished with value: 0.5821439343344034 and parameters: {'num_leaves': 84, 'learning_rate': 0.09305455555734686, 'feature_fraction': 0.7664943720204859, 'bagging_fraction': 0.8025891171923445, 'bagging_freq': 5, 'min_data_in_leaf': 99}. Best is trial 9 with value: 0.582297434129737.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476619781460532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476619781460532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8821310699872031, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8821310699872031\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476619781460532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476619781460532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8821310699872031, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8821310699872031\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476619781460532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476619781460532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8821310699872031, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8821310699872031\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01813\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476619781460532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476619781460532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8821310699872031, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8821310699872031\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:38:51,864] Trial 13 finished with value: 0.5796502359049486 and parameters: {'num_leaves': 63, 'learning_rate': 0.05180327932196994, 'feature_fraction': 0.8476619781460532, 'bagging_fraction': 0.8821310699872031, 'bagging_freq': 3, 'min_data_in_leaf': 68}. Best is trial 9 with value: 0.582297434129737.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.754312689158629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.754312689158629\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041534921454274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041534921454274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.754312689158629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.754312689158629\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041534921454274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041534921454274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.754312689158629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.754312689158629\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041534921454274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041534921454274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00882\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.754312689158629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.754312689158629\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041534921454274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041534921454274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:39:18,352] Trial 14 finished with value: 0.58309186289506 and parameters: {'num_leaves': 135, 'learning_rate': 0.0956177686461881, 'feature_fraction': 0.754312689158629, 'bagging_fraction': 0.8041534921454274, 'bagging_freq': 5, 'min_data_in_leaf': 66}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7395821484484542, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395821484484542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673850732421707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673850732421707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7395821484484542, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395821484484542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673850732421707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673850732421707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7395821484484542, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395821484484542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673850732421707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673850732421707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01193\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7395821484484542, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395821484484542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673850732421707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673850732421707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:39:49,082] Trial 15 finished with value: 0.5820496800741107 and parameters: {'num_leaves': 150, 'learning_rate': 0.0547856258894719, 'feature_fraction': 0.7395821484484542, 'bagging_fraction': 0.8673850732421707, 'bagging_freq': 7, 'min_data_in_leaf': 68}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8316602978734744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8316602978734744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9257867574540838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9257867574540838\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8316602978734744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8316602978734744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9257867574540838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9257867574540838\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8316602978734744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8316602978734744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9257867574540838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9257867574540838\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.02832\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8316602978734744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8316602978734744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9257867574540838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9257867574540838\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:40:17,985] Trial 16 finished with value: 0.5767175819204171 and parameters: {'num_leaves': 129, 'learning_rate': 0.026057602600848943, 'feature_fraction': 0.8316602978734744, 'bagging_fraction': 0.9257867574540838, 'bagging_freq': 6, 'min_data_in_leaf': 68}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8740748154635333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740748154635333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9919709260919555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9919709260919555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8740748154635333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740748154635333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9919709260919555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9919709260919555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8740748154635333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740748154635333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9919709260919555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9919709260919555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01639\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8740748154635333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740748154635333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9919709260919555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9919709260919555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:40:47,998] Trial 17 finished with value: 0.5806627959583773 and parameters: {'num_leaves': 132, 'learning_rate': 0.042059833527301915, 'feature_fraction': 0.8740748154635333, 'bagging_fraction': 0.9919709260919555, 'bagging_freq': 2, 'min_data_in_leaf': 63}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7473122510407316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473122510407316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7946786131204238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7946786131204238\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7473122510407316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473122510407316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7946786131204238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7946786131204238\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7473122510407316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473122510407316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7946786131204238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7946786131204238\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.03883\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7473122510407316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473122510407316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7946786131204238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7946786131204238\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:41:12,799] Trial 18 finished with value: 0.5728181485231704 and parameters: {'num_leaves': 96, 'learning_rate': 0.021310832305508415, 'feature_fraction': 0.7473122510407316, 'bagging_fraction': 0.7946786131204238, 'bagging_freq': 6, 'min_data_in_leaf': 38}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7959108519419777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959108519419777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.842242582110012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842242582110012\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7959108519419777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959108519419777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.842242582110012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842242582110012\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7959108519419777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959108519419777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.842242582110012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842242582110012\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01038\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7959108519419777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959108519419777\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.842242582110012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842242582110012\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:41:40,680] Trial 19 finished with value: 0.5822651183833509 and parameters: {'num_leaves': 133, 'learning_rate': 0.06882330167282533, 'feature_fraction': 0.7959108519419777, 'bagging_fraction': 0.842242582110012, 'bagging_freq': 4, 'min_data_in_leaf': 74}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8788931011382168, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8788931011382168\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7811571970590294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7811571970590294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8788931011382168, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8788931011382168\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7811571970590294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7811571970590294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8788931011382168, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8788931011382168\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7811571970590294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7811571970590294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.07848\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8788931011382168, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8788931011382168\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7811571970590294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7811571970590294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:42:02,688] Trial 20 finished with value: 0.5562724863735269 and parameters: {'num_leaves': 67, 'learning_rate': 0.010344410291439824, 'feature_fraction': 0.8788931011382168, 'bagging_fraction': 0.7811571970590294, 'bagging_freq': 4, 'min_data_in_leaf': 90}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8092779871357433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8092779871357433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8507185841289663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507185841289663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8092779871357433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8092779871357433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8507185841289663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507185841289663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8092779871357433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8092779871357433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8507185841289663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507185841289663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.0098\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8092779871357433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8092779871357433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8507185841289663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507185841289663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:42:30,170] Trial 21 finished with value: 0.5828225650085098 and parameters: {'num_leaves': 134, 'learning_rate': 0.07302344115410808, 'feature_fraction': 0.8092779871357433, 'bagging_fraction': 0.8507185841289663, 'bagging_freq': 4, 'min_data_in_leaf': 75}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8230058637055707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8230058637055707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8116506203133731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8116506203133731\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8230058637055707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8230058637055707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8116506203133731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8116506203133731\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8230058637055707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8230058637055707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8116506203133731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8116506203133731\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01055\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8230058637055707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8230058637055707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8116506203133731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8116506203133731\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:42:54,403] Trial 22 finished with value: 0.582356679664778 and parameters: {'num_leaves': 99, 'learning_rate': 0.08103810597187186, 'feature_fraction': 0.8230058637055707, 'bagging_fraction': 0.8116506203133731, 'bagging_freq': 5, 'min_data_in_leaf': 59}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8059058457553457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059058457553457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8226899269753917, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8226899269753917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8059058457553457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059058457553457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8226899269753917, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8226899269753917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8059058457553457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059058457553457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8226899269753917, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8226899269753917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01372\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8059058457553457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059058457553457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8226899269753917, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8226899269753917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:43:23,280] Trial 23 finished with value: 0.5810694357670682 and parameters: {'num_leaves': 97, 'learning_rate': 0.05786517243485634, 'feature_fraction': 0.8059058457553457, 'bagging_fraction': 0.8226899269753917, 'bagging_freq': 5, 'min_data_in_leaf': 58}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8287019160474557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8287019160474557\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8572736112068419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8572736112068419\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8287019160474557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8287019160474557\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8572736112068419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8572736112068419\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8287019160474557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8287019160474557\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8572736112068419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8572736112068419\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00927\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8287019160474557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8287019160474557\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8572736112068419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8572736112068419\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:43:57,259] Trial 24 finished with value: 0.5824832496714566 and parameters: {'num_leaves': 138, 'learning_rate': 0.07739371039874354, 'feature_fraction': 0.8287019160474557, 'bagging_fraction': 0.8572736112068419, 'bagging_freq': 6, 'min_data_in_leaf': 76}. Best is trial 14 with value: 0.58309186289506.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 1.00829\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:44:24,263] Trial 25 finished with value: 0.5833153801408967 and parameters: {'num_leaves': 140, 'learning_rate': 0.09964994195840352, 'feature_fraction': 0.8608806862181878, 'bagging_fraction': 0.864151941837032, 'bagging_freq': 6, 'min_data_in_leaf': 75}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.86756367988401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.86756367988401\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.904058677352676, subsample=1.0 will be ignored. Current value: bagging_fraction=0.904058677352676\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.86756367988401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.86756367988401\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.904058677352676, subsample=1.0 will be ignored. Current value: bagging_fraction=0.904058677352676\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.86756367988401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.86756367988401\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.904058677352676, subsample=1.0 will be ignored. Current value: bagging_fraction=0.904058677352676\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00882\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.86756367988401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.86756367988401\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.904058677352676, subsample=1.0 will be ignored. Current value: bagging_fraction=0.904058677352676\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:44:52,319] Trial 26 finished with value: 0.5827767843677962 and parameters: {'num_leaves': 122, 'learning_rate': 0.0894881808286754, 'feature_fraction': 0.86756367988401, 'bagging_fraction': 0.904058677352676, 'bagging_freq': 7, 'min_data_in_leaf': 88}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9106768301464707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9106768301464707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276486260485306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276486260485306\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9106768301464707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9106768301464707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276486260485306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276486260485306\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9106768301464707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9106768301464707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276486260485306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276486260485306\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01436\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9106768301464707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9106768301464707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276486260485306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276486260485306\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:45:30,472] Trial 27 finished with value: 0.5814033651463903 and parameters: {'num_leaves': 143, 'learning_rate': 0.046488692137198154, 'feature_fraction': 0.9106768301464707, 'bagging_fraction': 0.9276486260485306, 'bagging_freq': 6, 'min_data_in_leaf': 74}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9450337778072609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9450337778072609\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.852387928433535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.852387928433535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9450337778072609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9450337778072609\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.852387928433535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.852387928433535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9450337778072609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9450337778072609\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.852387928433535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.852387928433535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00904\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9450337778072609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9450337778072609\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.852387928433535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.852387928433535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:45:57,380] Trial 28 finished with value: 0.5822785832776785 and parameters: {'num_leaves': 124, 'learning_rate': 0.09743840453186363, 'feature_fraction': 0.9450337778072609, 'bagging_fraction': 0.852387928433535, 'bagging_freq': 2, 'min_data_in_leaf': 88}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7532469410292707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532469410292707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8944663869587208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8944663869587208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7532469410292707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532469410292707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8944663869587208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8944663869587208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7532469410292707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532469410292707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8944663869587208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8944663869587208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01646\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7532469410292707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532469410292707\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8944663869587208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8944663869587208\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:46:28,173] Trial 29 finished with value: 0.5806924187258978 and parameters: {'num_leaves': 138, 'learning_rate': 0.04122317702230585, 'feature_fraction': 0.7532469410292707, 'bagging_fraction': 0.8944663869587208, 'bagging_freq': 5, 'min_data_in_leaf': 74}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9352701820687757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9352701820687757\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8756161948648982, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8756161948648982\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9352701820687757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9352701820687757\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8756161948648982, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8756161948648982\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9352701820687757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9352701820687757\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8756161948648982, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8756161948648982\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01088\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9352701820687757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9352701820687757\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8756161948648982, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8756161948648982\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:46:58,307] Trial 30 finished with value: 0.582356679664778 and parameters: {'num_leaves': 149, 'learning_rate': 0.06230611945751641, 'feature_fraction': 0.9352701820687757, 'bagging_fraction': 0.8756161948648982, 'bagging_freq': 3, 'min_data_in_leaf': 53}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.871011808022783, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.871011808022783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9177635802350976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9177635802350976\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.871011808022783, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.871011808022783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9177635802350976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9177635802350976\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.871011808022783, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.871011808022783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9177635802350976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9177635802350976\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00881\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.871011808022783, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.871011808022783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9177635802350976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9177635802350976\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:47:23,959] Trial 31 finished with value: 0.5828117930930478 and parameters: {'num_leaves': 121, 'learning_rate': 0.09730962971111143, 'feature_fraction': 0.871011808022783, 'bagging_fraction': 0.9177635802350976, 'bagging_freq': 7, 'min_data_in_leaf': 88}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8536099108867314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8536099108867314\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.945705635206051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.945705635206051\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8536099108867314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8536099108867314\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.945705635206051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.945705635206051\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8536099108867314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8536099108867314\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.945705635206051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.945705635206051\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00987\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8536099108867314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8536099108867314\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.945705635206051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.945705635206051\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:47:51,323] Trial 32 finished with value: 0.582405153284357 and parameters: {'num_leaves': 116, 'learning_rate': 0.07899285946634789, 'feature_fraction': 0.8536099108867314, 'bagging_fraction': 0.945705635206051, 'bagging_freq': 7, 'min_data_in_leaf': 91}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8887398918290115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8887398918290115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9882053828018625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9882053828018625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8887398918290115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8887398918290115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9882053828018625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9882053828018625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8887398918290115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8887398918290115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9882053828018625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9882053828018625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8887398918290115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8887398918290115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9882053828018625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9882053828018625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:48:20,508] Trial 33 finished with value: 0.5825694249951526 and parameters: {'num_leaves': 128, 'learning_rate': 0.07063895502847355, 'feature_fraction': 0.8887398918290115, 'bagging_fraction': 0.9882053828018625, 'bagging_freq': 6, 'min_data_in_leaf': 84}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8586413915128043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8586413915128043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9618467009923648, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9618467009923648\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8586413915128043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8586413915128043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9618467009923648, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9618467009923648\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8586413915128043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8586413915128043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9618467009923648, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9618467009923648\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00855\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8586413915128043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8586413915128043\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9618467009923648, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9618467009923648\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:48:47,677] Trial 34 finished with value: 0.583005687571364 and parameters: {'num_leaves': 137, 'learning_rate': 0.09694690720024948, 'feature_fraction': 0.8586413915128043, 'bagging_fraction': 0.9618467009923648, 'bagging_freq': 7, 'min_data_in_leaf': 78}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8443281482127681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8443281482127681\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534607886186375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534607886186375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8443281482127681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8443281482127681\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534607886186375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534607886186375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8443281482127681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8443281482127681\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534607886186375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534607886186375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00939\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8443281482127681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8443281482127681\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534607886186375, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534607886186375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=81, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:49:17,047] Trial 35 finished with value: 0.5826609862765797 and parameters: {'num_leaves': 139, 'learning_rate': 0.07348080028638017, 'feature_fraction': 0.8443281482127681, 'bagging_fraction': 0.9534607886186375, 'bagging_freq': 5, 'min_data_in_leaf': 81}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8080193628977285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8080193628977285\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7818115910607449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7818115910607449\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8080193628977285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8080193628977285\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7818115910607449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7818115910607449\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8080193628977285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8080193628977285\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7818115910607449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7818115910607449\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00917\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8080193628977285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8080193628977285\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7818115910607449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7818115910607449\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:49:45,660] Trial 36 finished with value: 0.5825882758472112 and parameters: {'num_leaves': 136, 'learning_rate': 0.08453398208716993, 'feature_fraction': 0.8080193628977285, 'bagging_fraction': 0.7818115910607449, 'bagging_freq': 6, 'min_data_in_leaf': 77}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.781002014571044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.781002014571044\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967936756770392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967936756770392\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.781002014571044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.781002014571044\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967936756770392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967936756770392\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.781002014571044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.781002014571044\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967936756770392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967936756770392\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01786\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.781002014571044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.781002014571044\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967936756770392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967936756770392\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:50:06,432] Trial 37 finished with value: 0.5792812978003749 and parameters: {'num_leaves': 48, 'learning_rate': 0.06072361759924795, 'feature_fraction': 0.781002014571044, 'bagging_fraction': 0.967936756770392, 'bagging_freq': 7, 'min_data_in_leaf': 70}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.702527182249386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.702527182249386\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8411732711845155, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8411732711845155\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.702527182249386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.702527182249386\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8411732711845155, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8411732711845155\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.702527182249386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.702527182249386\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8411732711845155, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8411732711845155\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00848\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.702527182249386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.702527182249386\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8411732711845155, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8411732711845155\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:50:33,174] Trial 38 finished with value: 0.582437469030743 and parameters: {'num_leaves': 143, 'learning_rate': 0.09886474979428649, 'feature_fraction': 0.702527182249386, 'bagging_fraction': 0.8411732711845155, 'bagging_freq': 5, 'min_data_in_leaf': 63}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7306987638801206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7306987638801206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8625192144855224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8625192144855224\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7306987638801206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7306987638801206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8625192144855224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8625192144855224\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7306987638801206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7306987638801206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8625192144855224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8625192144855224\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01441\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7306987638801206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7306987638801206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8625192144855224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8625192144855224\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=95, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:51:01,298] Trial 39 finished with value: 0.5812310144989982 and parameters: {'num_leaves': 115, 'learning_rate': 0.050065784533388516, 'feature_fraction': 0.7306987638801206, 'bagging_fraction': 0.8625192144855224, 'bagging_freq': 6, 'min_data_in_leaf': 95}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8950939881403104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8950939881403104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7099942453309029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099942453309029\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8950939881403104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8950939881403104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7099942453309029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099942453309029\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8950939881403104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8950939881403104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7099942453309029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099942453309029\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.01041\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8950939881403104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8950939881403104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7099942453309029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099942453309029\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:51:25,031] Trial 40 finished with value: 0.5821277764612103 and parameters: {'num_leaves': 105, 'learning_rate': 0.08517817322755232, 'feature_fraction': 0.8950939881403104, 'bagging_fraction': 0.7099942453309029, 'bagging_freq': 4, 'min_data_in_leaf': 84}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.859694735577222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.859694735577222\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9232330224449743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9232330224449743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.859694735577222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.859694735577222\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9232330224449743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9232330224449743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.859694735577222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.859694735577222\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9232330224449743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9232330224449743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.0086\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.859694735577222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.859694735577222\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9232330224449743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9232330224449743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:51:51,023] Trial 41 finished with value: 0.5829949156559019 and parameters: {'num_leaves': 127, 'learning_rate': 0.09877926303809476, 'feature_fraction': 0.859694735577222, 'bagging_fraction': 0.9232330224449743, 'bagging_freq': 7, 'min_data_in_leaf': 77}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8613194928421471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8613194928421471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9722632038361162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9722632038361162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8613194928421471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8613194928421471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9722632038361162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9722632038361162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8613194928421471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8613194928421471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9722632038361162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9722632038361162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00952\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8613194928421471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8613194928421471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9722632038361162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9722632038361162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:52:18,202] Trial 42 finished with value: 0.5825478811642286 and parameters: {'num_leaves': 129, 'learning_rate': 0.07545940319400316, 'feature_fraction': 0.8613194928421471, 'bagging_fraction': 0.9722632038361162, 'bagging_freq': 7, 'min_data_in_leaf': 78}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.841545209444408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.841545209444408\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9434392588517307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9434392588517307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.841545209444408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.841545209444408\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9434392588517307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9434392588517307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.841545209444408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.841545209444408\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9434392588517307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9434392588517307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00814\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.841545209444408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.841545209444408\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9434392588517307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9434392588517307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:52:45,331] Trial 43 finished with value: 0.5832345907749316 and parameters: {'num_leaves': 144, 'learning_rate': 0.08729303823556048, 'feature_fraction': 0.841545209444408, 'bagging_fraction': 0.9434392588517307, 'bagging_freq': 7, 'min_data_in_leaf': 63}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8365236538674434, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8365236538674434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9340726406956472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9340726406956472\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8365236538674434, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8365236538674434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9340726406956472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9340726406956472\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8365236538674434, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8365236538674434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9340726406956472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9340726406956472\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00839\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8365236538674434, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8365236538674434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9340726406956472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9340726406956472\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:53:12,414] Trial 44 finished with value: 0.5830137665079604 and parameters: {'num_leaves': 144, 'learning_rate': 0.08796877364955187, 'feature_fraction': 0.8365236538674434, 'bagging_fraction': 0.9340726406956472, 'bagging_freq': 7, 'min_data_in_leaf': 48}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8410297679884605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8410297679884605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394104094126767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394104094126767\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8410297679884605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8410297679884605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394104094126767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394104094126767\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8410297679884605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8410297679884605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394104094126767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394104094126767\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00875\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8410297679884605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8410297679884605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394104094126767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394104094126767\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:53:39,458] Trial 45 finished with value: 0.5829356701208609 and parameters: {'num_leaves': 144, 'learning_rate': 0.08434728175088456, 'feature_fraction': 0.8410297679884605, 'bagging_fraction': 0.9394104094126767, 'bagging_freq': 7, 'min_data_in_leaf': 41}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8966973289413167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966973289413167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967489242919144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967489242919144\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8966973289413167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966973289413167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967489242919144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967489242919144\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8966973289413167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966973289413167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967489242919144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967489242919144\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.0101\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8966973289413167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8966973289413167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.967489242919144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.967489242919144\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:54:08,408] Trial 46 finished with value: 0.5824186181786846 and parameters: {'num_leaves': 150, 'learning_rate': 0.06689012862643896, 'feature_fraction': 0.8966973289413167, 'bagging_fraction': 0.967489242919144, 'bagging_freq': 6, 'min_data_in_leaf': 28}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9351182514170996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9351182514170996\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9392753298482016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9392753298482016\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9351182514170996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9351182514170996\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9392753298482016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9392753298482016\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9351182514170996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9351182514170996\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9392753298482016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9392753298482016\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.00888\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9351182514170996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9351182514170996\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9392753298482016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9392753298482016\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:54:36,671] Trial 47 finished with value: 0.5829787577827089 and parameters: {'num_leaves': 143, 'learning_rate': 0.08894813301366156, 'feature_fraction': 0.9351182514170996, 'bagging_fraction': 0.9392753298482016, 'bagging_freq': 7, 'min_data_in_leaf': 48}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8373123018335378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8373123018335378\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9084731771916095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9084731771916095\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8373123018335378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8373123018335378\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9084731771916095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9084731771916095\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8373123018335378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8373123018335378\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9084731771916095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9084731771916095\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.04497\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8373123018335378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8373123018335378\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9084731771916095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9084731771916095\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:55:05,851] Trial 48 finished with value: 0.5704564060581253 and parameters: {'num_leaves': 140, 'learning_rate': 0.016711244778337964, 'feature_fraction': 0.8373123018335378, 'bagging_fraction': 0.9084731771916095, 'bagging_freq': 6, 'min_data_in_leaf': 54}. Best is trial 25 with value: 0.5833153801408967.\n",
      "/var/folders/f7/wlltk9qd3_z7dnq_l2mxs5jc0000gn/T/ipykernel_14828/2396154904.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9621093163105013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9621093163105013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8930610795815405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8930610795815405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9621093163105013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9621093163105013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8930610795815405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8930610795815405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9621093163105013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9621093163105013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8930610795815405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8930610795815405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.0102\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9621093163105013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9621093163105013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8930610795815405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8930610795815405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 12:55:30,967] Trial 49 finished with value: 0.582399767326626 and parameters: {'num_leaves': 109, 'learning_rate': 0.08934690006405958, 'feature_fraction': 0.9621093163105013, 'bagging_fraction': 0.8930610795815405, 'bagging_freq': 7, 'min_data_in_leaf': 44}. Best is trial 25 with value: 0.5833153801408967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_leaves': 140, 'learning_rate': 0.09964994195840352, 'feature_fraction': 0.8608806862181878, 'bagging_fraction': 0.864151941837032, 'bagging_freq': 6, 'min_data_in_leaf': 75}\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114005, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -2.792041\n",
      "[LightGBM] [Info] Start training from score -2.806973\n",
      "[LightGBM] [Info] Start training from score -2.133589\n",
      "[LightGBM] [Info] Start training from score -1.488600\n",
      "[LightGBM] [Info] Start training from score -0.626954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.864151941837032, bagging_freq=6,\n",
       "               feature_fraction=0.8608806862181878,\n",
       "               learning_rate=0.09964994195840352, min_data_in_leaf=75,\n",
       "               num_class=5, num_leaves=140, objective=&#x27;multiclass&#x27;,\n",
       "               random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.864151941837032, bagging_freq=6,\n",
       "               feature_fraction=0.8608806862181878,\n",
       "               learning_rate=0.09964994195840352, min_data_in_leaf=75,\n",
       "               num_class=5, num_leaves=140, objective=&#x27;multiclass&#x27;,\n",
       "               random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.864151941837032, bagging_freq=6,\n",
       "               feature_fraction=0.8608806862181878,\n",
       "               learning_rate=0.09964994195840352, min_data_in_leaf=75,\n",
       "               num_class=5, num_leaves=140, objective='multiclass',\n",
       "               random_state=42)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Optuna for hyperparameter tuning\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "best_params = study.best_params\n",
    "final_model = lgb.LGBMClassifier(**best_params, objective='multiclass', num_class=5, random_state=42)\n",
    "final_model.fit(X_train_select, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n",
      "Final model accuracy on testing set: 0.5832857573733762\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "Y_test_pred = final_model.predict(X_test_select)\n",
    "accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "print(\"Final model accuracy on testing set:\", accuracy)\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, Y_test_pred, normalize='true')\n",
    "sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title(\"Confusion Matrix of the Optimized LightGBM Classifier\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8608806862181878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8608806862181878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864151941837032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864151941837032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=75, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=75\n"
     ]
    }
   ],
   "source": [
    "# Create the submission file\n",
    "X_submission['Score'] = final_model.predict(X_submission_select)\n",
    "submission = X_submission[['Id', 'Score']]\n",
    "submission.to_csv(\"./data/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venvT",
   "language": "python",
   "name": "venvt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
